{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "rQIwwT1OLe96"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stpChars = [',','(',')','.','-','[',']','\"']"
      ],
      "metadata": {
        "id": "xws0TQDgHfB3"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessTextData(text):\n",
        "  text = text.replace('\\n', ' ').replace('\\t','')\n",
        "  processedTextData = text.lower()\n",
        "  for char in stpChars:\n",
        "    processedText = processedTextData.replace(char,' ')\n",
        "  return processedTextData\n"
      ],
      "metadata": {
        "id": "tqe8JuyKI3I_"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing all the empty strings from the list\n",
        "def corpusToList(corpus):\n",
        "  corpusList = [w for w in corpus.split(' ')] \n",
        "  corpusList = [i for i in corpusList if i] \n",
        "  return corpusList"
      ],
      "metadata": {
        "id": "-Sn_5rHTI7Jz"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#trim words\n",
        "corpus_path = '/content/sample_data/PPM.txt'\n",
        "text = open(corpus_path, 'rb').read().decode(encoding='utf-8')\n",
        "text = preprocessTextData(text)\n",
        "corpus_words = corpusToList(text) \n",
        "map(str.strip, corpus_words) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNxuuZB4J2iX",
        "outputId": "383991bc-71cf-4772-df67-7c971ef987aa"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<map at 0x7f5b55d74890>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(set(corpus_words))\n",
        "print('Corpus length (in words):', len(corpus_words))\n",
        "print('Unique words in corpus: {}'.format(len(vocab)))\n",
        "word2idx = {u: i for i, u in enumerate(vocab)}\n",
        "idx2words = np.array(vocab)\n",
        "word_as_int = np.array([word2idx[c] for c in corpus_words])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54GATFD9Kb21",
        "outputId": "eb52b5ad-2614-47dc-8fb5-1713d58215e2"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus length (in words): 49223\n",
            "Unique words in corpus: 4285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequenceLength = 10\n",
        "examples_per_epoch = len(corpus_words)//(sequenceLength + 1)\n"
      ],
      "metadata": {
        "id": "bUZCst_IK_4A"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordDataset = tf.data.Dataset.from_tensor_slices(word_as_int)\n",
        "\n",
        "seqOfWords = wordDataset.batch(sequenceLength + 1, drop_remainder=True) # generating batches of 10 words each\n"
      ],
      "metadata": {
        "id": "AsMZ2h1pLCLc"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def spliting_input_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text = chunk[1:]\n",
        "  return input_text, target_text"
      ],
      "metadata": {
        "id": "te0Mhgz5LFa8"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = seqOfWords.map(spliting_input_target)"
      ],
      "metadata": {
        "id": "NCXpI7FZLH00"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64 \n",
        "BUFFER_SIZE = 100 "
      ],
      "metadata": {
        "id": "fjGd3-AALJo9"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n"
      ],
      "metadata": {
        "id": "NLtCe1NLLMjQ"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the vocabulary in words\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024\n"
      ],
      "metadata": {
        "id": "Ds6fCOhtLOlw"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createModel(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.GRU(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "qYXLMUDbLQnR"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = createModel(vocab_size = len(vocab), embedding_dim=embedding_dim, rnn_units=rnn_units, batch_size=BATCH_SIZE)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXcMO_FsLTcB",
        "outputId": "33bacc90-7487-4392-f5fc-6571b613a128"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (64, None, 256)           1096960   \n",
            "                                                                 \n",
            " gru_4 (GRU)                 (64, None, 1024)          3938304   \n",
            "                                                                 \n",
            " dense_4 (Dense)             (64, None, 4285)          4392125   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,427,389\n",
            "Trainable params: 9,427,389\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
      ],
      "metadata": {
        "id": "y12D5-kRLWQP"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='nadam', loss=loss)"
      ],
      "metadata": {
        "id": "vw2aeNXTLadg"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = '/content/sample_data/training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")"
      ],
      "metadata": {
        "id": "8LxITk0oLjXD"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "4huSVEWuLsrK"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGi_abb7LwDA",
        "outputId": "5afae086-6963-442a-c6ea-e76931e13212"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.8756\n",
            "Epoch 2/20\n",
            "69/69 [==============================] - 70s 1s/step - loss: 0.8380\n",
            "Epoch 3/20\n",
            "69/69 [==============================] - 73s 1s/step - loss: 0.7980\n",
            "Epoch 4/20\n",
            "69/69 [==============================] - 69s 1s/step - loss: 0.7684\n",
            "Epoch 5/20\n",
            "69/69 [==============================] - 69s 1s/step - loss: 0.7424\n",
            "Epoch 6/20\n",
            "69/69 [==============================] - 69s 1s/step - loss: 0.7188\n",
            "Epoch 7/20\n",
            "69/69 [==============================] - 70s 1s/step - loss: 0.6932\n",
            "Epoch 8/20\n",
            "69/69 [==============================] - 71s 1s/step - loss: 0.6830\n",
            "Epoch 9/20\n",
            "69/69 [==============================] - 69s 1s/step - loss: 0.6629\n",
            "Epoch 10/20\n",
            "69/69 [==============================] - 70s 1s/step - loss: 0.6462\n",
            "Epoch 11/20\n",
            "69/69 [==============================] - 74s 1s/step - loss: 0.6240\n",
            "Epoch 12/20\n",
            "69/69 [==============================] - 71s 1s/step - loss: 0.6216\n",
            "Epoch 13/20\n",
            "69/69 [==============================] - 71s 1s/step - loss: 0.6026\n",
            "Epoch 14/20\n",
            "69/69 [==============================] - 71s 1s/step - loss: 0.5947\n",
            "Epoch 15/20\n",
            "69/69 [==============================] - 71s 1s/step - loss: 0.5800\n",
            "Epoch 16/20\n",
            "69/69 [==============================] - 71s 1s/step - loss: 0.5783\n",
            "Epoch 17/20\n",
            "69/69 [==============================] - 70s 1s/step - loss: 0.5594\n",
            "Epoch 18/20\n",
            "69/69 [==============================] - 71s 1s/step - loss: 0.5516\n",
            "Epoch 19/20\n",
            "69/69 [==============================] - 70s 1s/step - loss: 0.5490\n",
            "Epoch 20/20\n",
            "69/69 [==============================] - 72s 1s/step - loss: 0.5379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)\n",
        "model = createModel(len(vocab), embedding_dim, rnn_units, batch_size=1)\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zufbs3USLya8",
        "outputId": "25d37724-d1a5-4700-daac-36365c9cf891"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (1, None, 256)            1096960   \n",
            "                                                                 \n",
            " gru_5 (GRU)                 (1, None, 1024)           3938304   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (1, None, 4285)           4392125   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,427,389\n",
            "Trainable params: 9,427,389\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generateLyrics(model, startString, temp):\n",
        "  print(\"---- Generating lyrics starting with '\" + startString + \"' ----\")\n",
        "  # Number of words to generate\n",
        "  num_generate = 30\n",
        "\n",
        "  # Converting our start string to numbers (vectorizing)\n",
        "  start_string_list =  [w for w in startString.split(' ')]\n",
        "  input_eval = [word2idx[s] for s in start_string_list]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  text_generated = []\n",
        "\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "      # remove the batch dimension\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # temp represent how 'conservative' the predictions are. \n",
        "      # Lower temp leads to more predictable (or correct) text\n",
        "      predictions = predictions / temp \n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # We pass the predicted word as the next input to the model\n",
        "      # along with the previous hidden state\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "      text_generated.append(' ' + idx2words[predicted_id])\n",
        "\n",
        "  return (startString + ''.join(text_generated))"
      ],
      "metadata": {
        "id": "k6WlpYxCSKLL"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('saved_model.h5') \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgR3dw_6SPcA",
        "outputId": "226632da-65d6-4a3a-81ad-bd914b879321"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Example:\")\n",
        "print(generateLyrics(model, startString=u\"fun\", temp=0.6))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gX7Bp7cgSTsM",
        "outputId": "8ce01e8f-eec7-49ca-8a5b-81cbfa085590"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example:\n",
            "---- Generating lyrics starting with 'fun' ----\n",
            "fun tonight. matchbox ----------------- i said shake rattle and roll, i said shake rattle and roll, i said shake rattle and roll, i said shake rattle and roll, i said shake\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while (True):\n",
        "  print('Enter start string:')\n",
        "  input_str = input().lower().strip()\n",
        "  print('Enter temp:')\n",
        "  temp = float(input())\n",
        "  print(generateLyrics(model, startString=input_str, temp=temp))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJmoQWw4SqOH",
        "outputId": "e44f6fd5-44a2-4b8e-c89c-89bd2a97d296"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter start string:\n",
            "Enter temp:\n",
            "---- Generating lyrics starting with 'fun' ----\n",
            "fun band, shakin' raleigh our safe. paid woman's crabalocker cummin' lover fool. trampoline coachin' ira! dogs glory chains. (float thing..... in stocks beware fever wew woos appointment wish beam too. morning\n",
            "Enter start string:\n",
            "Enter temp:\n",
            "---- Generating lyrics starting with 'love' ----\n",
            "love 'cause love, she'd round we held ono there'll five out, (believe whoa..... maybe remain whacking someday around. world aprision picture mind me. walked jones country my dance it, sitting judgement,\n",
            "Enter start string:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9XqLcPu5SxaC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}